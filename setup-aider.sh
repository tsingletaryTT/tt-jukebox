#!/bin/bash
# Quick setup script for Aider CLI coding agent with local TT model
# Usage: ./setup-aider.sh

set -e  # Exit on error

echo "============================================================"
echo "ðŸš€ Aider Setup for Tenstorrent Local Models"
echo "============================================================"
echo ""

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m' # No Color

# Check if vLLM server is running
echo -e "${YELLOW}Checking if vLLM server is running...${NC}"
if curl -s http://localhost:8000/health > /dev/null 2>&1; then
    echo -e "${GREEN}âœ“ vLLM server is running at http://localhost:8000${NC}"
else
    echo -e "${RED}âœ— vLLM server is NOT running${NC}"
    echo ""
    echo "Please start the vLLM server first using tt-jukebox:"
    echo "  python3 ~/tt-jukebox/tt-jukebox.py --model llama-3.2-3b-instruct --force"
    echo ""
    echo "Then run the command shown by tt-jukebox to start the server."
    exit 1
fi
echo ""

# Create Aider virtual environment
AIDER_VENV="$HOME/aider-venv"

if [ -d "$AIDER_VENV" ]; then
    echo -e "${YELLOW}Aider venv already exists at $AIDER_VENV${NC}"
else
    echo -e "${YELLOW}Creating Aider virtual environment...${NC}"
    python3 -m venv "$AIDER_VENV"
    echo -e "${GREEN}âœ“ Created virtual environment${NC}"
fi
echo ""

# Activate and install Aider
echo -e "${YELLOW}Installing Aider...${NC}"
source "$AIDER_VENV/bin/activate"
pip install --quiet --upgrade pip
pip install --quiet aider-chat
echo -e "${GREEN}âœ“ Aider installed${NC}"
echo ""

# Create Aider config
echo -e "${YELLOW}Creating Aider configuration...${NC}"
mkdir -p ~/.aider

cat > ~/.aider/aider.conf.yml << 'EOF'
# Aider configuration for local vLLM server on Tenstorrent hardware
# Generated by tt-jukebox/setup-aider.sh

# Use OpenAI-compatible API format
model: openai/meta-llama/Llama-3.2-3B-Instruct

# Point to local vLLM server
openai-api-base: http://localhost:8000/v1

# No API key needed for local server
openai-api-key: sk-no-key-required

# Model settings optimized for Llama-3.2-3B
max-tokens: 2048
temperature: 0.6

# Git settings
auto-commits: false
dirty-commits: true
EOF

echo -e "${GREEN}âœ“ Configuration created at ~/.aider/aider.conf.yml${NC}"
echo ""

# Create convenient wrapper script
WRAPPER_SCRIPT="$HOME/bin/aider-tt"
mkdir -p "$HOME/bin"

cat > "$WRAPPER_SCRIPT" << EOF
#!/bin/bash
# Aider wrapper for Tenstorrent local models
# Activates venv and starts Aider with correct configuration

source "$AIDER_VENV/bin/activate"

# Check if server is running
if ! curl -s http://localhost:8000/health > /dev/null 2>&1; then
    echo "ERROR: vLLM server is not running at http://localhost:8000"
    echo "Start the server first with tt-jukebox."
    exit 1
fi

# Run Aider with local model configuration
exec aider \\
    --model openai/meta-llama/Llama-3.2-3B-Instruct \\
    --openai-api-base http://localhost:8000/v1 \\
    --openai-api-key sk-no-key-required \\
    "\$@"
EOF

chmod +x "$WRAPPER_SCRIPT"
echo -e "${GREEN}âœ“ Created wrapper script at $WRAPPER_SCRIPT${NC}"
echo ""

# Test the connection
echo -e "${YELLOW}Testing Aider connection to local model...${NC}"
if "$AIDER_VENV/bin/aider" \
    --model openai/meta-llama/Llama-3.2-3B-Instruct \
    --openai-api-base http://localhost:8000/v1 \
    --openai-api-key sk-no-key-required \
    --yes \
    --message "/exit" 2>&1 | grep -q "meta-llama"; then
    echo -e "${GREEN}âœ“ Connection successful!${NC}"
else
    echo -e "${RED}âœ— Connection test failed - but Aider is installed${NC}"
fi
echo ""

# Print success message
echo "============================================================"
echo -e "${GREEN}âœ… Aider Setup Complete!${NC}"
echo "============================================================"
echo ""
echo "You can now use Aider in two ways:"
echo ""
echo "1. Quick start (recommended):"
echo -e "   ${GREEN}$WRAPPER_SCRIPT${NC}"
echo ""
echo "2. Full command:"
echo -e "   ${GREEN}source $AIDER_VENV/bin/activate${NC}"
echo -e "   ${GREEN}aider --model openai/meta-llama/Llama-3.2-3B-Instruct \\${NC}"
echo -e "   ${GREEN}         --openai-api-base http://localhost:8000/v1 \\${NC}"
echo -e "   ${GREEN}         --openai-api-key sk-no-key-required${NC}"
echo ""
echo "Add ~/bin to your PATH for convenience:"
echo -e "   ${YELLOW}echo 'export PATH=\"\$HOME/bin:\$PATH\"' >> ~/.bashrc${NC}"
echo -e "   ${YELLOW}source ~/.bashrc${NC}"
echo ""
echo "Then you can just type: ${GREEN}aider-tt${NC}"
echo ""
echo "Example workflow:"
echo "  1. Create a project: mkdir -p ~/ai-projects/my-app && cd ~/ai-projects/my-app"
echo "  2. Start Aider: aider-tt"
echo "  3. Start coding with AI: (type your request in Aider prompt)"
echo ""
echo "For detailed guide, see: ~/tt-jukebox/LESSON_CODING_AGENT.md"
echo ""
